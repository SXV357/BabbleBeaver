# Any new models that someone wants to integrate should be added here

# gpt models
[gpt-3.5-turbo]
context_length = 16385

[gpt-3.5-turbo-1106]
context_length = 16385

[gpt-4-turbo-preview]
context_length = 128000

[gpt-4-turbo]
context_length = 128000

[gpt-4o-mini]
context_length = 128000

# gemini models
[gemini-pro]
context_length = 32000

[gemini-1.5-pro]
context_length = 2000000

[gemini-1.5-flash]
context_length = 1000000

# ollama models
[llama3.1]
context_length = 128000
model_id = meta-llama/Meta-Llama-3.1-8B-Instruct

[llama3.1:70b]
context_length = 128000
model_id = meta-llama/Meta-Llama-3.1-70B-Instruct

[gemma2]
context_length = 8192
model_id = google/gemma-2-9b-it

[gemma2:27b]
context_length = 8192
model_id = google/gemma-2-27b-it

[mistral-nemo]
context_length = 128000
model_id = mistralai/Mistral-Nemo-Instruct-2407

[mistral-large]
context_length = 128000
model_id = mistralai/Mistral-Large-Instruct-2407

[qwen2]
context_length = 131072
model_id = Qwen/Qwen2-7B-Instruct

[qwen2:72b]
context_length = 131072
model_id = Qwen/Qwen2-72B-Instruct

[phi3]
context_length = 128000
model_id = microsoft/Phi-3-mini-128k-instruct

[phi3:14b]
context_length = 128000
model_id = microsoft/Phi-3-medium-128k-instruct

[mistral]
context_length = 32000
model_id = mistralai/Mistral-7B-Instruct-v0.2

[mixtral]
context_length = 32000
model_id = mistralai/Mixtral-8x7B-Instruct-v0.1

[mixtral:8x22b]
context_length = 64000
model_id = mistralai/Mixtral-8x22B-Instruct-v0.1

[codegemma]
context_length = 8192
model_id = google/codegemma-7b

[command-r]
context_length = 128000
model_id = CohereForAI/c4ai-command-r-v01

[command-r-plus]
context_length = 128000
model_id = CohereForAI/c4ai-command-r-plus

[llama3]
context_length = 8192
model_id = meta-llama/Meta-Llama-3-8B-Instruct

[llama3:70b]
context_length = 8192
model_id = meta-llama/Meta-Llama-3-70B-Instruct

[gemma]
context_length = 8192
model_id = google/gemma-1.1-7b-it

[gemma:2b]
context_length = 8192
model_id = google/gemma-1.1-2b-it

[llama2]
context_length = 4096
model_id = meta-llama/Llama-2-7b-chat-hf

[llama2:13b]
context_length = 4096
model_id = meta-llama/Llama-2-13b-chat-hf

[llama2:70b]
context_length = 4096
model_id = meta-llama/Llama-2-70b-chat-hf

[codellama]
context_length = 16000
model_id = codellama/CodeLlama-7b-Instruct-hf

[codellama:13b]
context_length = 16000
model_id = codellama/CodeLlama-13b-Instruct-hf

[codellama:34b]
context_length = 16000
model_id = codellama/CodeLlama-34b-Instruct-hf

[codellama:70b]
context_length = 16000
model_id = codellama/CodeLlama-70b-Instruct-hf